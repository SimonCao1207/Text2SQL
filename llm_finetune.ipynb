{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from const import EHR_VALID_DATA_PATH, EHR_VALID_LABEL_PATH, EHR_TRAIN_DATA_PATH, EHR_TRAIN_LABEL_PATH\n",
    "import json\n",
    "\n",
    "with open(os.path.join(EHR_VALID_DATA_PATH), \"r\") as f:\n",
    "    valid_data = json.load(f)\n",
    "with open(os.path.join(EHR_VALID_LABEL_PATH), \"r\") as f:\n",
    "    valid_label = json.load(f)\n",
    "with open(os.path.join(EHR_TRAIN_DATA_PATH), \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(os.path.join(EHR_TRAIN_LABEL_PATH), \"r\") as f:\n",
    "    train_label = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5124 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5124/5124 [00:00<00:00, 53560.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from const import SYSTEM_PROMPT\n",
    "messages = []\n",
    "\n",
    "# Train using only answerable data\n",
    "for item in tqdm(train_data['data']):\n",
    "    question = item['question']\n",
    "    id = item['id']    \n",
    "    sql = train_label.get(item['id'])  \n",
    "    if sql == 'null': # Filter out unanswerable questions\n",
    "        continue\n",
    "    message = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": sql}\n",
    "        ]\n",
    "    }\n",
    "    messages.append(message)\n",
    "print(len(messages)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': \"Given the following SQL tables and SQL assumptions you must follow, your job is to write queries given a user’s request.\\n IMPORTANT: If you think you cannot predict the SQL accurately, you must answer with 'null'.\"}, {'role': 'user', 'content': \"What's the number of patients who were laceration of intercostal blood vessels, left side, initial encounter diagnosed since 2100?\"}, {'role': 'assistant', 'content': \"SELECT COUNT( DISTINCT admissions.subject_id ) FROM admissions WHERE admissions.hadm_id IN ( SELECT diagnoses_icd.hadm_id FROM diagnoses_icd WHERE diagnoses_icd.icd_code = ( SELECT d_icd_diagnoses.icd_code FROM d_icd_diagnoses WHERE d_icd_diagnoses.long_title = 'laceration of intercostal blood vessels, left side, initial encounter' ) AND strftime('%Y',diagnoses_icd.charttime) >= '2100' )\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save answerable data as jsonl\n",
    "with open(\"messages.jsonl\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for entry in messages:\n",
    "        json.dump(entry, f, ensure_ascii=False)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning model\n",
    "Before finetuning the model, expect the cost by running `python finetunning_analysis.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "open_ai_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if open_ai_key is None:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Uncomment to fine-tune, run this with caution (it costed about 8$)\n",
    "\"\"\"\n",
    "\n",
    "# fileobject=client.files.create(\n",
    "#   file=open(\"messages.jsonl\", \"rb\"),\n",
    "#   purpose=\"fine-tune\"\n",
    "# )\n",
    "\n",
    "# client.fine_tuning.jobs.create(\n",
    "#   training_file=fileobject.id, \n",
    "#   model=\"gpt-4o-mini-2024-07-18\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-RTgrxafzVr7N0fkM59Xg5ScS', created_at=1741233639, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::B7xHlv2W', finished_at=1741235888, hyperparameters=Hyperparameters(batch_size=9, learning_rate_multiplier=1.8, n_epochs=3), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-I29zp03jrmNMs68Tgl6V7SnV', result_files=['file-WE2gKdvEgcPZTdga8AF8HA'], seed=474235012, status='succeeded', trained_tokens=2624619, training_file='file-TkXpQXQBrF7ENuY5U2NvrR', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size=9, learning_rate_multiplier=1.8, n_epochs=3)), type='supervised'), user_provided_suffix=None, metadata=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-RTgrxafzVr7N0fkM59Xg5ScS\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# List fine-tuning jobs\n",
    "jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "print(len(list(jobs)))  # Number of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.fine_tuning.jobs.cancel(\"ftjob-YvxKrztlXNiKWVPmVhHRYHbm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
