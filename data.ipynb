{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ehr_valid_data 1163 1163\n",
      "ehr_train_data 5124 5124\n",
      "ehr_test_data 1167 1167\n",
      "valid_data 20 20\n",
      "test_data 1008\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data\n",
    "from const import (\n",
    "    EHR_TRAIN_DATA_PATH, \n",
    "    EHR_TRAIN_LABEL_PATH, \n",
    "    EHR_VALID_DATA_PATH, \n",
    "    EHR_VALID_LABEL_PATH, \n",
    "    EHR_TEST_DATA_PATH, \n",
    "    EHR_TEST_LABEL_PATH, \n",
    "    TEST_DATA_PATH, \n",
    "    VALID_DATA_PATH, \n",
    "    VALID_LABEL_PATH\n",
    ")\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(os.path.join(TEST_DATA_PATH), \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "ehr_valid_data, ehr_valid_labels = load_data(EHR_VALID_DATA_PATH, EHR_VALID_LABEL_PATH)\n",
    "ehr_train_data, ehr_train_labels = load_data(EHR_TRAIN_DATA_PATH, EHR_TRAIN_LABEL_PATH)\n",
    "ehr_test_data, ehr_test_labels = load_data(EHR_TEST_DATA_PATH, EHR_TEST_LABEL_PATH)\n",
    "\n",
    "valid_data, valid_labels = load_data(VALID_DATA_PATH, VALID_LABEL_PATH)\n",
    "test_data, _ = load_data(TEST_DATA_PATH, None, is_test=True)\n",
    "\n",
    "print(\"ehr_valid_data\", len(ehr_valid_data[\"data\"]), len(ehr_valid_labels))\n",
    "print(\"ehr_train_data\", len(ehr_train_data[\"data\"]), len(ehr_train_labels)) \n",
    "print(\"ehr_test_data\", len(ehr_test_data[\"data\"]), len(ehr_test_labels))\n",
    "\n",
    "print(\"valid_data\", len(valid_data[\"data\"]), len(valid_labels))\n",
    "print(\"test_data\", len(test_data[\"data\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/1163 questions are not answerable in the validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>293a491c440d62e67c686f47</td>\n",
       "      <td>What is the maximum number of drugs and their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fc91b305e4be2838d4a5b0c5</td>\n",
       "      <td>Is there a gender restriction on potassium chl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6d76715f3b8643d188af9795</td>\n",
       "      <td>Do they have a gender limit to lidocaine-prilo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dec6c9f45523ef859e8d0977</td>\n",
       "      <td>Is there any remaining appointment for patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5497eb668de1ff020fd4e774</td>\n",
       "      <td>Translate icu equipment usage data into a main...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "14  293a491c440d62e67c686f47   \n",
       "15  fc91b305e4be2838d4a5b0c5   \n",
       "19  6d76715f3b8643d188af9795   \n",
       "20  dec6c9f45523ef859e8d0977   \n",
       "31  5497eb668de1ff020fd4e774   \n",
       "\n",
       "                                             question  \n",
       "14  What is the maximum number of drugs and their ...  \n",
       "15  Is there a gender restriction on potassium chl...  \n",
       "19  Do they have a gender limit to lidocaine-prilo...  \n",
       "20  Is there any remaining appointment for patient...  \n",
       "31  Translate icu equipment usage data into a main...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_null_labels = []\n",
    "for idx, label in ehr_valid_labels.items():\n",
    "    if (label == \"null\"):\n",
    "        list_null_labels.append(idx)\n",
    "print(f\"{len(list_null_labels)}/{len(ehr_valid_labels)} questions are not answerable in the validation set\")\n",
    "\n",
    "test_df = pd.DataFrame(ehr_valid_data[\"data\"])\n",
    "null_test_df = test_df[test_df['id'].isin(list_null_labels)]\n",
    "\n",
    "null_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/1167 questions are not answerable in the validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f70d67ccafc181a6d95a5da</td>\n",
       "      <td>When was back to godhead written?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a5348117eb65b1c2d5c291ae</td>\n",
       "      <td>Call the it department to report a system issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b093fb10a7007c37b5ff6f9</td>\n",
       "      <td>What is primary and non-contributory under the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cc6a1305faf59ceadd9f9270</td>\n",
       "      <td>When does patient 1819 cease to be in a quaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>af5df4194e2b15e8dc1e2251</td>\n",
       "      <td>What are the latest guidelines for managing ic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "2   3f70d67ccafc181a6d95a5da   \n",
       "3   a5348117eb65b1c2d5c291ae   \n",
       "4   8b093fb10a7007c37b5ff6f9   \n",
       "13  cc6a1305faf59ceadd9f9270   \n",
       "19  af5df4194e2b15e8dc1e2251   \n",
       "\n",
       "                                             question  \n",
       "2                   When was back to godhead written?  \n",
       "3   Call the it department to report a system issu...  \n",
       "4   What is primary and non-contributory under the...  \n",
       "13  When does patient 1819 cease to be in a quaran...  \n",
       "19  What are the latest guidelines for managing ic...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_null_labels = []\n",
    "for idx, label in ehr_test_labels.items():\n",
    "    if (label == \"null\"):\n",
    "        list_null_labels.append(idx)\n",
    "print(f\"{len(list_null_labels)}/{len(ehr_test_labels)} questions are not answerable in the test set\")\n",
    "\n",
    "test_df = pd.DataFrame(ehr_test_data[\"data\"])\n",
    "null_test_df = test_df[test_df['id'].isin(list_null_labels)]\n",
    "null_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_null_labels = []\n",
    "for idx, label in ehr_train_labels.items():\n",
    "    if (label == \"null\"):\n",
    "        list_null_labels.append(idx)\n",
    "print(f\"{len(list_null_labels)}/{len(ehr_train_labels)} questions are not answerable in the train set\")\n",
    "\n",
    "train_df = pd.DataFrame(ehr_train_data[\"data\"])\n",
    "null_train_df = train_df[train_df['id'].isin(list_null_labels)]\n",
    "null_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which performing physicians were involved in procedures for patients admitted via emergency room admission?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(null_test_df))\n",
    "print(null_test_df.iloc[idx]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import TEST_DATA_PATH\n",
    "import os\n",
    "import json\n",
    "\n",
    "with open(os.path.join(TEST_DATA_PATH), \"r\") as f:\n",
    "    test_data  = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a similarity check function\n",
    "def is_similar(test_question, data, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Check if a test question is similar to any question in valid data\n",
    "    using a simple string similarity measure\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    for item in data:\n",
    "        question, idx = item[\"question\"], item[\"id\"]\n",
    "        similarity = SequenceMatcher(None, test_question.lower(), \n",
    "                                    question.lower()).ratio()\n",
    "        if similarity >= threshold:\n",
    "            return True, similarity, question, idx\n",
    "    return False, 0, None, None\n",
    "\n",
    "def _save(file_name, similar_items):\n",
    "    output_path = os.path.join(\"tmp\", file_name)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump({\"similar_items\": similar_items}, f, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(similar_items)} similar items to {output_path}\")\n",
    "\n",
    "def _check(ehr_data, file_name):\n",
    "    # Check each test item for similarity\n",
    "    similar_items = []\n",
    "    for item in tqdm(test_data[\"data\"]):\n",
    "        id, question = item[\"id\"], item[\"question\"]\n",
    "        is_sim, score, match, match_id = is_similar(question, ehr_data[\"data\"])\n",
    "        \n",
    "        if is_sim:\n",
    "            similar_items.append({\n",
    "                \"test_id\": id,\n",
    "                \"test_question\": question,\n",
    "                \"similarity_score\": score,\n",
    "                \"matching_question\": match,\n",
    "                \"matching_id\": match_id\n",
    "            })\n",
    "\n",
    "    print(f\"Found {len(similar_items)} similar items from ehr_valid_data out of {len(test_data['data'])} test items\")\n",
    "    _save(file_name, similar_items)\n",
    "\n",
    "def _display(file_name):\n",
    "    with open(os.path.join(\"tmp\", file_name), \"r\") as f:\n",
    "        similar_items = json.load(f)[\"similar_items\"]\n",
    "    # Display some examples of similar items if any were found\n",
    "\n",
    "    print(f\"Found {len(similar_items)} similar items out of {len(test_data['data'])} test items\")\n",
    "    # for i, item in enumerate(similar_items[:5]):  # Show first 5 similar items\n",
    "    #     print(f\"\\nSimilar item #{i+1}:\")\n",
    "    #     print(f\"Test ID: {item['test_id']}\")\n",
    "    #     print(f\"Test question: {item['test_question']}\")\n",
    "    #     print(f\"Similarity score: {item['similarity_score']:.2f}\")\n",
    "    #     print(f\"Matching question: {item['matching_question']}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129 similar items out of 1008 test items\n"
     ]
    }
   ],
   "source": [
    "# _check(ehr_valid_data, \"ehr_valid_data_similar_items.json\")\n",
    "_display(\"ehr_valid_data_similar_items.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 similar items out of 1008 test items\n"
     ]
    }
   ],
   "source": [
    "# _check(ehr_test_data, \"ehr_test_data_similar_items.json\") \n",
    "_display(\"ehr_test_data_similar_items.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 similar items out of 1008 test items\n"
     ]
    }
   ],
   "source": [
    "# _check(ehr_train_data, \"ehr_train_data_similar_items.json\")\n",
    "_display(\"ehr_train_data_similar_items.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
